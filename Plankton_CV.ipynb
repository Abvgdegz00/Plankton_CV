{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb165be5",
   "metadata": {},
   "source": [
    "# Классификация изображений планктона\n",
    "\n",
    "В данной работе рассматривается задача классификации изображений планктона.\n",
    "\n",
    "Цель работы - построить устойчивый пайплайн классификации изображений и провести сравнительный анализ различных стратегий обучения нейронных сетей, включая обучение с нуля и transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18df864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, matthews_corrcoef, balanced_accuracy_score\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864fa8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da50d2d",
   "metadata": {},
   "source": [
    "## Анализ датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136978a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы: ['Leegaardiella_ovalis', 'Mesodinium_sp', 'amoeba']\n",
      "Кол-во: {0: 10, 1: 676, 2: 14}\n",
      "Всего: 700\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_dir = Path('/data')\n",
    "img_dim = 224\n",
    "\n",
    "# Получение списка классов\n",
    "class_names = sorted([d.name for d in base_dir.iterdir() if d.is_dir()])\n",
    "idx_map = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "# Создаем список всех изображений с их метками\n",
    "files = []\n",
    "for cls in class_names:\n",
    "    cls_dir = base_dir / cls\n",
    "    for img in cls_dir.glob(\"*.png\"):\n",
    "        files.append((img, idx_map[cls]))\n",
    "\n",
    "# Подсчет количества изображений в каждом классе\n",
    "stats = Counter(l for _, l in files)\n",
    "\n",
    "print(f\"Классы: {class_names}\")\n",
    "print(f\"Кол-во: {dict(stats)}\")\n",
    "print(f\"Всего: {len(files)}\")\n",
    "\n",
    "# Визуализация распределения классов\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(class_names, [stats[i] for i in range(len(class_names))])\n",
    "ax.set_title(\"Распределение по классам\")\n",
    "ax.set_xlabel(\"Класс\")\n",
    "ax.set_ylabel(\"Изображений\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467ce36",
   "metadata": {},
   "source": [
    "Датасет характеризуется выраженным дисбалансом:\n",
    "Класс Mesodinium_sp содержит на порядок больше изображений, чем два других. В таких условиях использование accuracy в качестве основной метрики может быть вводящим в заблуждение, поэтому в дальнейшем основное внимание уделяется macro F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3153d",
   "metadata": {},
   "source": [
    "## Предобработка изображений\n",
    "\n",
    "Для обеспечения стабильного обучения нейронной сети все изображения приводятся к единому формату:\n",
    "\n",
    "* Изменение размера до 224×224 пикселей\n",
    "\n",
    "* Нормализация по статистике ImageNet\n",
    "\n",
    "Аугментации данных (только для обучающей выборки):\n",
    "\n",
    "* Повороты и отражения (планктон свободно плавает в пространстве)\n",
    "\n",
    "* Небольшие аффинные преобразования (имитация движения в воде)\n",
    "\n",
    "* Легкая коррекция цвета (вариации освещения микроскопа)\n",
    "\n",
    "* Минимальное размытие (изменения фокусировки)\n",
    "\n",
    "Недопустимые аугментации:\n",
    "\n",
    "* RandomPerspective - не соответствует оптике микроскопа\n",
    "\n",
    "* ElasticTransform/GridDistortion - искажает морфологию организмов\n",
    "\n",
    "* Агрессивный RandomCrop - отсекает структурные элементы\n",
    "\n",
    "* Mixup/CutMix - биологически некорректное смешивание\n",
    "\n",
    "* Сильное изменение цвета - цвет является важным признаком\n",
    "\n",
    "* Резкая бинаризация - теряет градиенты интенсивности\n",
    "\n",
    "* Черно-белые преобразования - уничтожают цветовые признаки\n",
    "\n",
    "Обоснование: Микроскопические изображения планктона должны сохранять морфологическую целостность и цветовые характеристики, так как они являются ключевыми для идентификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3089e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageNet_mean = [0.485, 0.456, 0.406]\n",
    "ImageNet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_dim, img_dim)),\n",
    "    \n",
    "    # Ориентация:\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    \n",
    "    # Реалистичные искажения:\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05), shear=(-2, 2, -2, 2)),\n",
    "    \n",
    "    # Изменения цвета:\n",
    "    transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.05),\n",
    "    \n",
    "    # Дополнительные аугментации:\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.3))], p=0.2),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(ImageNet_mean, ImageNet_std),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_dim, img_dim)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(ImageNet_mean, ImageNet_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9538b",
   "metadata": {},
   "source": [
    "### Dataset, балансировка классов и кросс-валидация:\n",
    "\n",
    "Для компенсации дисбаланса используется взвешенное семплирование, позволяющее формировать батчи с равномерным представлением классов. Каждое изображение получает вес, обратно пропорциональный размеру его класса, что увеличивает вероятность выбора примеров из миноритарных классов.\n",
    "\n",
    "Для надежной оценки на малом датасете применяется стратифицированная кросс-валидация, которая сохраняет пропорции классов в каждом фолде и исключает утечку данных между обучающей и валидационной выборками.\n",
    "Аугментации применяются только к обучающей выборке, валидационные данные преобразуются только для изменения размера и нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9676fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanktonDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def create_cv_dataloaders(samples, class_names, batch_size=8, n_splits=5, fold=0, random_state=42):\n",
    "    # Подготавливаем данные для StratifiedKFold\n",
    "    paths = np.array([str(p) for p, _ in samples])\n",
    "    labels = np.array([l for _, l in samples])\n",
    "    \n",
    "    # Создаем KFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Получаем индексы для текущего фолда\n",
    "    all_indices = list(skf.split(paths, labels))\n",
    "    train_idx, val_idx = all_indices[fold]\n",
    "    \n",
    "    train_samples = [(Path(p), l) for p, l in zip(paths[train_idx], labels[train_idx])]\n",
    "    val_samples = [(Path(p), l) for p, l in zip(paths[val_idx], labels[val_idx])]\n",
    "    \n",
    "    # Создаем Dataset\n",
    "    train_ds = PlanktonDataset(train_samples, train_transform)\n",
    "    val_ds = PlanktonDataset(val_samples, val_transform)\n",
    "    \n",
    "    # Балансировка для тренировочной выборки\n",
    "    train_labels_fold = [label for _, label in train_samples]\n",
    "    class_counts = Counter(train_labels_fold)\n",
    "    weights = [1.0 / class_counts[label] for label in train_labels_fold]\n",
    "    \n",
    "    sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "    \n",
    "    # Создаем DataLoader\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, train_samples, val_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1958f",
   "metadata": {},
   "source": [
    "### Архитектуры моделей\n",
    "\n",
    "В работе сравниваются три подхода:\n",
    "\n",
    "1. **Собственная CNN**\n",
    "\n",
    "2. **Предобученная ConvNeXt-Tiny**  \n",
    "   Тестируются три стратегии fine-tuning:\n",
    "   - `classifier_only` - обучение только финального классификационного слоя\n",
    "   - `partial` - разморозка последнего residual-блока\n",
    "   - `full` - полное дообучение всей сети\n",
    "\n",
    "3. **Предобученная EfficientNet-B4**  \n",
    "   Тестируется с теми же стратегиями fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1632257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собственная CNN\n",
    "class PlanktonNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 32, 7, 2, 3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1102f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобученная ConvNeXt-Tiny\n",
    "def build_convnext_tiny(strategy, num_classes):\n",
    "    model = models.convnext_tiny(\n",
    "        weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1\n",
    "    )\n",
    "    \n",
    "    if strategy == \"classifier_only\":\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    elif strategy == \"partial\":\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in model.features[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    elif strategy == \"full\":\n",
    "        pass\n",
    "\n",
    "    in_features = model.classifier[2].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        model.classifier[0],\n",
    "        model.classifier[1],\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795fc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобученная EfficientNet-B4\n",
    "def build_efficientnet_b4(strategy, num_classes):\n",
    "    model = models.efficientnet_b4(\n",
    "        weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1\n",
    "    )\n",
    "    \n",
    "    if strategy == \"classifier_only\":\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    elif strategy == \"partial\":\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.features[5:].parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    elif strategy == \"full\":\n",
    "        pass\n",
    "    \n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.4, inplace=True),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c3074",
   "metadata": {},
   "source": [
    "### Процесс обучения модели\n",
    "\n",
    "Обучение проводится со следующими настройками:\n",
    "\n",
    "* Optimizer: Adam с фильтрацией по requires_grad для поддержки стратегий fine-tuning\n",
    "\n",
    "* Loss function: CrossEntropyLoss с весами классов для компенсации дисбаланса\n",
    "\n",
    "* Ранняя остановка: по validation loss с patience = 5 эпох\n",
    "\n",
    "* Максимальное число эпох: 40\n",
    "\n",
    "Для оценки используется accuracy и macro F1-score, причем последний является основной метрикой благодаря устойчивости к дисбалансу классов. Дополнительно применяются взвешенные веса в функции потерь, пропорциональные обратному размеру классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b12ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    batch_size,\n",
    "    epochs=40,\n",
    "    lr=1e-3,\n",
    "    patience=5,\n",
    "    model_name=\"Model\",\n",
    "    strategy=\"from_scratch\",\n",
    "    total_experiments=1,\n",
    "    experiment_idx=1\n",
    "):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=lr\n",
    "    )\n",
    "\n",
    "    class_counts = Counter([label for _, label in train_loader.dataset.samples])\n",
    "    class_weights = torch.tensor([\n",
    "        1.0 / class_counts[i] for i in range(len(class_counts))\n",
    "    ]).to(device)\n",
    "    class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    best_loss = float(\"inf\")\n",
    "    patience_ctr = 0\n",
    "    best_state = None\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    desc_text = (\n",
    "        f\"[{experiment_idx}/{total_experiments}] \"\n",
    "        f\"{model_name}-{strategy} bs={batch_size}\"\n",
    "    )\n",
    "\n",
    "    epoch_bar = tqdm(\n",
    "        range(epochs),\n",
    "        desc=desc_text,\n",
    "        ascii=True,\n",
    "        leave=True,\n",
    "        dynamic_ncols=False\n",
    "    )\n",
    "\n",
    "    for epoch in epoch_bar:\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(imgs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        epoch_bar.set_postfix({\n",
    "            \"train_loss\": f\"{train_loss:.4f}\",\n",
    "            \"val_loss\": f\"{val_loss:.4f}\",\n",
    "            \"val_acc\": f\"{val_acc:.3f}\"\n",
    "        })\n",
    "\n",
    "        # Ранняя остановка\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= patience:\n",
    "                epoch_bar.write(f\"Ранняя остановка на эпохе: {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718af67",
   "metadata": {},
   "source": [
    "### Оценка качества модели\n",
    "\n",
    "Для объективной оценки в условиях дисбаланса классов используется расширенный набор метрик:\n",
    "\n",
    "* **Accuracy** - общая точность классификации\n",
    "* **Balanced Accuracy** - точность, усредненная по классам\n",
    "* **Macro F1-score** - основная метрика сравнения, усредняет F1 по всем классам без учета их размера\n",
    "* **Cohen's Kappa** - учитывает вероятность случайного угадывания\n",
    "* **Matthews Correlation Coefficient** - корреляция между предсказаниями и истинными метками\n",
    "* **Weighted F1-score** - учитывает размер классов, показывает общую эффективность\n",
    "* **Per-class F1-score** - позволяет выявить проблемные классы\n",
    "\n",
    "Macro F1-score является основной метрикой для сравнения моделей, так как наиболее устойчива к дисбалансу классов в датасете и обеспечивает равное внимание к миноритарным классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d55ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            outputs = model(imgs.to(device))\n",
    "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    report = classification_report(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        target_names=class_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"balanced_accuracy\": balanced_acc,\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"cohens_kappa\": kappa,\n",
    "        \"matthews_corrcoef\": mcc,\n",
    "        \"per_class_f1\": {cls: report[cls][\"f1-score\"] for cls in class_names}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24589038",
   "metadata": {},
   "source": [
    "### Экспериментальная часть\n",
    "\n",
    "Проводится серия экспериментов с кросс-валидацией для сравнения различных подходов.\n",
    "\n",
    "**Тестируемые архитектуры:**\n",
    "\n",
    "* PlanktonNet\n",
    "\n",
    "* ConvNeXt-Tiny\n",
    "\n",
    "* EfficientNet-B4\n",
    "\n",
    "**Параметры экспериментов:**\n",
    "\n",
    "* Кросс-валидация: 3 фолда (стратифицированная)\n",
    "\n",
    "* Размеры батча: 8 и 16 изображений\n",
    "\n",
    "**Стратегии fine-tuning:**\n",
    "\n",
    "* classifier_only - обучение только классификатора\n",
    "\n",
    "* partial - частичное дообучение последних слоев\n",
    "\n",
    "* full - полное дообучение\n",
    "\n",
    "Каждая модель оценивается по полному набору метрик с акцентом на Macro F1-score для корректного сравнения при дисбалансе классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d60521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comprehensive_cv_experiments(files, class_names, batch_sizes=[8, 16], n_splits=3):\n",
    "    results = []\n",
    "    \n",
    "    strategies = [\"classifier_only\", \"partial\", \"full\"]\n",
    "    \n",
    "    # Рассчитываем общее количество экспериментов\n",
    "    total_experiments = len(batch_sizes) * n_splits * (1 + len(strategies) * 2)\n",
    "    experiment_count = 0\n",
    "    \n",
    "    for bs in batch_sizes:\n",
    "        print(f\"Размер батча: {bs}\")\n",
    "        \n",
    "        for fold in range(n_splits):\n",
    "            print(f\"\\nФолд {fold+1}/{n_splits} (batch_size={bs})\")\n",
    "            \n",
    "            train_loader, val_loader, _, _ = create_cv_dataloaders(\n",
    "                files, class_names, batch_size=bs, n_splits=n_splits, fold=fold\n",
    "            )\n",
    "            \n",
    "            experiment_count += 1\n",
    "            print(f\"\\nЭксперимент {experiment_count}/{total_experiments}\")\n",
    "            print(f\"Модель: PlanktonNet (from_scratch)\")\n",
    "            \n",
    "            model = PlanktonNet(num_classes=len(class_names))\n",
    "            model, history = train_model(\n",
    "                model, train_loader, val_loader, \n",
    "                batch_size=bs,\n",
    "                total_experiments=total_experiments,\n",
    "                experiment_idx=experiment_count,\n",
    "                lr=1e-3, model_name=\"PlanktonNet\", strategy=\"from_scratch\"\n",
    "            )\n",
    "            metrics = evaluate_model(model, val_loader)\n",
    "            results.append({\n",
    "                \"model\": \"PlanktonNet\",\n",
    "                \"strategy\": \"from_scratch\",\n",
    "                \"batch_size\": bs,\n",
    "                \"fold\": fold + 1,\n",
    "                **metrics\n",
    "            })\n",
    "            \n",
    "            for strategy in strategies:\n",
    "                experiment_count += 1\n",
    "                print(f\"\\nЭксперимент {experiment_count}/{total_experiments}\")\n",
    "                print(f\"Модель: ConvNeXt-Tiny ({strategy})\")\n",
    "                \n",
    "                model = build_convnext_tiny(strategy, num_classes=len(class_names))\n",
    "                lr = 5e-5 if strategy != \"classifier_only\" else 1e-3\n",
    "                model, history = train_model(\n",
    "                    model, train_loader, val_loader,\n",
    "                    batch_size=bs,\n",
    "                    total_experiments=total_experiments,\n",
    "                    experiment_idx=experiment_count,\n",
    "                    lr=lr, model_name=\"ConvNeXt-Tiny\", strategy=strategy\n",
    "                )\n",
    "                metrics = evaluate_model(model, val_loader)\n",
    "                results.append({\n",
    "                    \"model\": \"ConvNeXt-Tiny\",\n",
    "                    \"strategy\": strategy,\n",
    "                    \"batch_size\": bs,\n",
    "                    \"fold\": fold + 1,\n",
    "                    \"learning_rate\": lr,\n",
    "                    **metrics\n",
    "                })\n",
    "                \n",
    "            for strategy in strategies:\n",
    "                experiment_count += 1\n",
    "                print(f\"\\nЭксперимент {experiment_count}/{total_experiments}\")\n",
    "                print(f\"Модель: EfficientNet-B4 ({strategy})\")\n",
    "                \n",
    "                model = build_efficientnet_b4(strategy, num_classes=len(class_names))\n",
    "                lr = 5e-5 if strategy != \"classifier_only\" else 1e-3\n",
    "                model, history = train_model(\n",
    "                    model, train_loader, val_loader,\n",
    "                    batch_size=bs,\n",
    "                    total_experiments=total_experiments,\n",
    "                    experiment_idx=experiment_count,\n",
    "                    lr=lr, model_name=\"EfficientNet-B4\", strategy=strategy\n",
    "                )\n",
    "                metrics = evaluate_model(model, val_loader)\n",
    "                results.append({\n",
    "                    \"model\": \"EfficientNet-B4\",\n",
    "                    \"strategy\": strategy,\n",
    "                    \"batch_size\": bs,\n",
    "                    \"fold\": fold + 1,\n",
    "                    \"learning_rate\": lr,\n",
    "                    **metrics\n",
    "                })\n",
    "            \n",
    "            print(f\"\\nЗавершен фолд {fold+1}/{n_splits}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "184c90c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер батча: 8\n",
      "\n",
      "Фолд 1/3 (batch_size=8)\n",
      "\n",
      "Эксперимент 1/42\n",
      "Модель: PlanktonNet (from_scratch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/42] PlanktonNet-from_scratch bs=8:  12%|#2        | 5/40 [00:37<04:23,  7.53s/it, train_loss=0.2548, val_loss=3.9154, val_acc=0.030] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 2/42\n",
      "Модель: ConvNeXt-Tiny (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2/42] ConvNeXt-Tiny-classifier_only bs=8:  68%|######7   | 27/40 [03:01<01:27,  6.72s/it, train_loss=0.0012, val_loss=0.0806, val_acc=0.970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 28\n",
      "\n",
      "Эксперимент 3/42\n",
      "Модель: ConvNeXt-Tiny (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3/42] ConvNeXt-Tiny-partial bs=8:  45%|####5     | 18/40 [02:02<02:29,  6.79s/it, train_loss=0.0004, val_loss=0.0211, val_acc=0.996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 19\n",
      "\n",
      "Эксперимент 4/42\n",
      "Модель: ConvNeXt-Tiny (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4/42] ConvNeXt-Tiny-full bs=8:  25%|##5       | 10/40 [01:28<04:26,  8.88s/it, train_loss=0.0022, val_loss=0.0370, val_acc=0.996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 11\n",
      "\n",
      "Эксперимент 5/42\n",
      "Модель: EfficientNet-B4 (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5/42] EfficientNet-B4-classifier_only bs=8:  15%|#5        | 6/40 [00:45<04:18,  7.62s/it, train_loss=0.1661, val_loss=2.1434, val_acc=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 7\n",
      "\n",
      "Эксперимент 6/42\n",
      "Модель: EfficientNet-B4 (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[6/42] EfficientNet-B4-partial bs=8:  12%|#2        | 5/40 [00:46<05:27,  9.36s/it, train_loss=0.1051, val_loss=2.8489, val_acc=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 7/42\n",
      "Модель: EfficientNet-B4 (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[7/42] EfficientNet-B4-full bs=8:  12%|#2        | 5/40 [00:53<06:11, 10.62s/it, train_loss=0.1074, val_loss=2.7467, val_acc=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Завершен фолд 1/3\n",
      "\n",
      "Фолд 2/3 (batch_size=8)\n",
      "\n",
      "Эксперимент 8/42\n",
      "Модель: PlanktonNet (from_scratch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[8/42] PlanktonNet-from_scratch bs=8:  30%|###       | 12/40 [01:19<03:04,  6.60s/it, train_loss=0.1484, val_loss=5.8596, val_acc=0.026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 13\n",
      "\n",
      "Эксперимент 9/42\n",
      "Модель: ConvNeXt-Tiny (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[9/42] ConvNeXt-Tiny-classifier_only bs=8:  30%|###       | 12/40 [01:24<03:16,  7.00s/it, train_loss=0.0088, val_loss=0.5081, val_acc=0.785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 13\n",
      "\n",
      "Эксперимент 10/42\n",
      "Модель: ConvNeXt-Tiny (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10/42] ConvNeXt-Tiny-partial bs=8:  40%|####      | 16/40 [01:49<02:44,  6.84s/it, train_loss=0.0015, val_loss=0.0064, val_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 17\n",
      "\n",
      "Эксперимент 11/42\n",
      "Модель: ConvNeXt-Tiny (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/42] ConvNeXt-Tiny-full bs=8:  62%|######2   | 25/40 [03:27<02:04,  8.32s/it, train_loss=0.0002, val_loss=0.0006, val_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 26\n",
      "\n",
      "Эксперимент 12/42\n",
      "Модель: EfficientNet-B4 (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12/42] EfficientNet-B4-classifier_only bs=8:  12%|#2        | 5/40 [00:38<04:30,  7.73s/it, train_loss=0.2434, val_loss=1.8422, val_acc=0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 13/42\n",
      "Модель: EfficientNet-B4 (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13/42] EfficientNet-B4-partial bs=8:  12%|#2        | 5/40 [00:46<05:28,  9.38s/it, train_loss=0.1408, val_loss=3.2750, val_acc=0.030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 14/42\n",
      "Модель: EfficientNet-B4 (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14/42] EfficientNet-B4-full bs=8:  12%|#2        | 5/40 [00:51<05:58, 10.25s/it, train_loss=0.1183, val_loss=3.4257, val_acc=0.030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Завершен фолд 2/3\n",
      "\n",
      "Фолд 3/3 (batch_size=8)\n",
      "\n",
      "Эксперимент 15/42\n",
      "Модель: PlanktonNet (from_scratch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/42] PlanktonNet-from_scratch bs=8:  25%|##5       | 10/40 [01:07<03:21,  6.73s/it, train_loss=0.3283, val_loss=5.0003, val_acc=0.021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 11\n",
      "\n",
      "Эксперимент 16/42\n",
      "Модель: ConvNeXt-Tiny (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/42] ConvNeXt-Tiny-classifier_only bs=8:  95%|#########5| 38/40 [04:11<00:13,  6.62s/it, train_loss=0.0022, val_loss=0.0691, val_acc=0.970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 39\n",
      "\n",
      "Эксперимент 17/42\n",
      "Модель: ConvNeXt-Tiny (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/42] ConvNeXt-Tiny-partial bs=8:  60%|######    | 24/40 [02:38<01:45,  6.60s/it, train_loss=0.0003, val_loss=0.0071, val_acc=0.991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 25\n",
      "\n",
      "Эксперимент 18/42\n",
      "Модель: ConvNeXt-Tiny (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/42] ConvNeXt-Tiny-full bs=8:  35%|###5      | 14/40 [01:58<03:40,  8.49s/it, train_loss=0.0003, val_loss=0.0060, val_acc=0.991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 15\n",
      "\n",
      "Эксперимент 19/42\n",
      "Модель: EfficientNet-B4 (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/42] EfficientNet-B4-classifier_only bs=8:  12%|#2        | 5/40 [00:39<04:35,  7.87s/it, train_loss=0.2205, val_loss=2.0809, val_acc=0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 20/42\n",
      "Модель: EfficientNet-B4 (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/42] EfficientNet-B4-partial bs=8:  12%|#2        | 5/40 [00:45<05:21,  9.18s/it, train_loss=0.1378, val_loss=3.4301, val_acc=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 21/42\n",
      "Модель: EfficientNet-B4 (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21/42] EfficientNet-B4-full bs=8:  12%|#2        | 5/40 [00:51<06:03, 10.37s/it, train_loss=0.1374, val_loss=3.1679, val_acc=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Завершен фолд 3/3\n",
      "Размер батча: 16\n",
      "\n",
      "Фолд 1/3 (batch_size=16)\n",
      "\n",
      "Эксперимент 22/42\n",
      "Модель: PlanktonNet (from_scratch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22/42] PlanktonNet-from_scratch bs=16:  38%|###7      | 15/40 [01:32<02:34,  6.19s/it, train_loss=0.1713, val_loss=8.2139, val_acc=0.021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 16\n",
      "\n",
      "Эксперимент 23/42\n",
      "Модель: ConvNeXt-Tiny (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23/42] ConvNeXt-Tiny-classifier_only bs=16:  75%|#######5  | 30/40 [03:08<01:02,  6.30s/it, train_loss=0.0020, val_loss=0.1079, val_acc=0.970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 31\n",
      "\n",
      "Эксперимент 24/42\n",
      "Модель: ConvNeXt-Tiny (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[24/42] ConvNeXt-Tiny-partial bs=16:  62%|######2   | 25/40 [02:34<01:32,  6.18s/it, train_loss=0.0005, val_loss=0.0194, val_acc=0.996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 26\n",
      "\n",
      "Эксперимент 25/42\n",
      "Модель: ConvNeXt-Tiny (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[25/42] ConvNeXt-Tiny-full bs=16:  42%|####2     | 17/40 [03:37<04:53, 12.78s/it, train_loss=0.0003, val_loss=0.0344, val_acc=0.996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 18\n",
      "\n",
      "Эксперимент 26/42\n",
      "Модель: EfficientNet-B4 (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[26/42] EfficientNet-B4-classifier_only bs=16:  12%|#2        | 5/40 [00:36<04:14,  7.27s/it, train_loss=0.2238, val_loss=2.1458, val_acc=0.051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 27/42\n",
      "Модель: EfficientNet-B4 (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[27/42] EfficientNet-B4-partial bs=16:  12%|#2        | 5/40 [00:38<04:27,  7.66s/it, train_loss=0.2238, val_loss=2.5379, val_acc=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 28/42\n",
      "Модель: EfficientNet-B4 (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28/42] EfficientNet-B4-full bs=16:  12%|#2        | 5/40 [00:43<05:07,  8.79s/it, train_loss=0.2421, val_loss=2.6295, val_acc=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Завершен фолд 1/3\n",
      "\n",
      "Фолд 2/3 (batch_size=16)\n",
      "\n",
      "Эксперимент 29/42\n",
      "Модель: PlanktonNet (from_scratch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29/42] PlanktonNet-from_scratch bs=16:  32%|###2      | 13/40 [01:20<02:47,  6.20s/it, train_loss=0.1734, val_loss=2.6070, val_acc=0.030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 14\n",
      "\n",
      "Эксперимент 30/42\n",
      "Модель: ConvNeXt-Tiny (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30/42] ConvNeXt-Tiny-classifier_only bs=16:  78%|#######7  | 31/40 [03:15<00:56,  6.31s/it, train_loss=0.0024, val_loss=0.2394, val_acc=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 32\n",
      "\n",
      "Эксперимент 31/42\n",
      "Модель: ConvNeXt-Tiny (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[31/42] ConvNeXt-Tiny-partial bs=16: 100%|##########| 40/40 [04:01<00:00,  6.03s/it, train_loss=0.0005, val_loss=0.0008, val_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент 32/42\n",
      "Модель: ConvNeXt-Tiny (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[32/42] ConvNeXt-Tiny-full bs=16:  90%|######### | 36/40 [07:24<00:49, 12.36s/it, train_loss=0.0002, val_loss=0.0026, val_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 37\n",
      "\n",
      "Эксперимент 33/42\n",
      "Модель: EfficientNet-B4 (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[33/42] EfficientNet-B4-classifier_only bs=16:  12%|#2        | 5/40 [00:36<04:12,  7.22s/it, train_loss=0.2618, val_loss=1.8152, val_acc=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 34/42\n",
      "Модель: EfficientNet-B4 (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[34/42] EfficientNet-B4-partial bs=16:  12%|#2        | 5/40 [00:37<04:24,  7.55s/it, train_loss=0.2710, val_loss=3.0117, val_acc=0.030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 35/42\n",
      "Модель: EfficientNet-B4 (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[35/42] EfficientNet-B4-full bs=16:  12%|#2        | 5/40 [00:45<05:16,  9.05s/it, train_loss=0.2938, val_loss=2.9585, val_acc=0.030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Завершен фолд 2/3\n",
      "\n",
      "Фолд 3/3 (batch_size=16)\n",
      "\n",
      "Эксперимент 36/42\n",
      "Модель: PlanktonNet (from_scratch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[36/42] PlanktonNet-from_scratch bs=16:  52%|#####2    | 21/40 [02:09<01:56,  6.15s/it, train_loss=0.2655, val_loss=5.3284, val_acc=0.026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 22\n",
      "\n",
      "Эксперимент 37/42\n",
      "Модель: ConvNeXt-Tiny (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[37/42] ConvNeXt-Tiny-classifier_only bs=16: 100%|##########| 40/40 [04:02<00:00,  6.05s/it, train_loss=0.0018, val_loss=0.1425, val_acc=0.940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент 38/42\n",
      "Модель: ConvNeXt-Tiny (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[38/42] ConvNeXt-Tiny-partial bs=16:  68%|######7   | 27/40 [02:49<01:21,  6.27s/it, train_loss=0.0009, val_loss=0.0202, val_acc=0.991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 28\n",
      "\n",
      "Эксперимент 39/42\n",
      "Модель: ConvNeXt-Tiny (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[39/42] ConvNeXt-Tiny-full bs=16:  55%|#####5    | 22/40 [04:37<03:47, 12.62s/it, train_loss=0.0003, val_loss=0.0031, val_acc=0.996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 23\n",
      "\n",
      "Эксперимент 40/42\n",
      "Модель: EfficientNet-B4 (classifier_only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[40/42] EfficientNet-B4-classifier_only bs=16:  15%|#5        | 6/40 [00:41<03:56,  6.95s/it, train_loss=0.2464, val_loss=1.9562, val_acc=0.056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 7\n",
      "\n",
      "Эксперимент 41/42\n",
      "Модель: EfficientNet-B4 (partial)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[41/42] EfficientNet-B4-partial bs=16:  12%|#2        | 5/40 [00:40<04:41,  8.03s/it, train_loss=0.3095, val_loss=2.5882, val_acc=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Эксперимент 42/42\n",
      "Модель: EfficientNet-B4 (full)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[42/42] EfficientNet-B4-full bs=16:  12%|#2        | 5/40 [00:43<05:03,  8.68s/it, train_loss=0.2876, val_loss=2.4787, val_acc=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка на эпохе: 6\n",
      "\n",
      "Завершен фолд 3/3\n"
     ]
    }
   ],
   "source": [
    "full_results_df = run_comprehensive_cv_experiments(files, class_names, batch_sizes=[8, 16], n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a56737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сводные результаты экспериментов:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>balanced_accuracy_mean</th>\n",
       "      <th>balanced_accuracy_std</th>\n",
       "      <th>macro_f1_mean</th>\n",
       "      <th>macro_f1_std</th>\n",
       "      <th>cohens_kappa_mean</th>\n",
       "      <th>cohens_kappa_std</th>\n",
       "      <th>matthews_corrcoef_mean</th>\n",
       "      <th>matthews_corrcoef_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>classifier_only</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>0.5092</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.2135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>classifier_only</td>\n",
       "      <td>16</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.5117</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.5815</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>full</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.0541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>full</td>\n",
       "      <td>16</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.0339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>partial</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>partial</td>\n",
       "      <td>16</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>classifier_only</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>classifier_only</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.0053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>full</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>full</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>partial</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>partial</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PlanktonNet</td>\n",
       "      <td>from_scratch</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PlanktonNet</td>\n",
       "      <td>from_scratch</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.0480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model         strategy  batch_size  accuracy_mean  accuracy_std  \\\n",
       "0     ConvNeXt-Tiny  classifier_only           8         0.9085        0.1066   \n",
       "1     ConvNeXt-Tiny  classifier_only          16         0.9342        0.0390   \n",
       "2     ConvNeXt-Tiny             full           8         0.9957        0.0043   \n",
       "3     ConvNeXt-Tiny             full          16         0.9971        0.0025   \n",
       "4     ConvNeXt-Tiny          partial           8         0.9957        0.0043   \n",
       "5     ConvNeXt-Tiny          partial          16         0.9957        0.0043   \n",
       "6   EfficientNet-B4  classifier_only           8         0.0429        0.0044   \n",
       "7   EfficientNet-B4  classifier_only          16         0.0715        0.0311   \n",
       "8   EfficientNet-B4             full           8         0.0343        0.0042   \n",
       "9   EfficientNet-B4             full          16         0.0343        0.0042   \n",
       "10  EfficientNet-B4          partial           8         0.0343        0.0042   \n",
       "11  EfficientNet-B4          partial          16         0.0343        0.0042   \n",
       "12      PlanktonNet     from_scratch           8         0.0257        0.0042   \n",
       "13      PlanktonNet     from_scratch          16         0.0257        0.0043   \n",
       "\n",
       "    balanced_accuracy_mean  balanced_accuracy_std  macro_f1_mean  \\\n",
       "0                   0.9139                 0.0825         0.6933   \n",
       "1                   0.9501                 0.0375         0.6979   \n",
       "2                   0.9985                 0.0015         0.9614   \n",
       "3                   0.9717                 0.0477         0.9678   \n",
       "4                   0.9712                 0.0473         0.9556   \n",
       "5                   0.9712                 0.0473         0.9556   \n",
       "6                   0.6696                 0.0029         0.0509   \n",
       "7                   0.6795                 0.0120         0.0718   \n",
       "8                   0.6667                 0.0000         0.0474   \n",
       "9                   0.6667                 0.0000         0.0478   \n",
       "10                  0.6667                 0.0000         0.0485   \n",
       "11                  0.6667                 0.0000         0.0484   \n",
       "12                  0.5167                 0.0601         0.0518   \n",
       "13                  0.5333                 0.1333         0.0828   \n",
       "\n",
       "    macro_f1_std  cohens_kappa_mean  cohens_kappa_std  matthews_corrcoef_mean  \\\n",
       "0         0.1612             0.5092            0.2794                  0.5711   \n",
       "1         0.1074             0.5117            0.1749                  0.5815   \n",
       "2         0.0429             0.9438            0.0572                  0.9463   \n",
       "3         0.0279             0.9597            0.0349                  0.9609   \n",
       "4         0.0425             0.9417            0.0572                  0.9443   \n",
       "5         0.0425             0.9417            0.0572                  0.9443   \n",
       "6         0.0021             0.0180            0.0015                  0.0960   \n",
       "7         0.0215             0.0202            0.0011                  0.1029   \n",
       "8         0.0101             0.0176            0.0026                  0.0976   \n",
       "9         0.0014             0.0179            0.0017                  0.0992   \n",
       "10        0.0063             0.0170            0.0015                  0.0973   \n",
       "11        0.0081             0.0181            0.0022                  0.1002   \n",
       "12        0.0043             0.0098            0.0024                  0.0744   \n",
       "13        0.0380             0.0097            0.0048                  0.1211   \n",
       "\n",
       "    matthews_corrcoef_std  \n",
       "0                  0.2135  \n",
       "1                  0.1267  \n",
       "2                  0.0541  \n",
       "3                  0.0339  \n",
       "4                  0.0542  \n",
       "5                  0.0542  \n",
       "6                  0.0030  \n",
       "7                  0.0053  \n",
       "8                  0.0124  \n",
       "9                  0.0012  \n",
       "10                 0.0064  \n",
       "11                 0.0112  \n",
       "12                 0.0179  \n",
       "13                 0.0480  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучшие результаты по каждой модели (по Macro F1):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>macro_f1_mean</th>\n",
       "      <th>macro_f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>full</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.0429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt-Tiny</td>\n",
       "      <td>full</td>\n",
       "      <td>16</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>classifier_only</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EfficientNet-B4</td>\n",
       "      <td>classifier_only</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PlanktonNet</td>\n",
       "      <td>from_scratch</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PlanktonNet</td>\n",
       "      <td>from_scratch</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.0380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model         strategy  batch_size  macro_f1_mean  macro_f1_std\n",
       "2     ConvNeXt-Tiny             full           8         0.9614        0.0429\n",
       "3     ConvNeXt-Tiny             full          16         0.9678        0.0279\n",
       "6   EfficientNet-B4  classifier_only           8         0.0509        0.0021\n",
       "7   EfficientNet-B4  classifier_only          16         0.0718        0.0215\n",
       "12      PlanktonNet     from_scratch           8         0.0518        0.0043\n",
       "13      PlanktonNet     from_scratch          16         0.0828        0.0380"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Агрегация результатов экспериментов\n",
    "summary = full_results_df.groupby(['model', 'strategy', 'batch_size']).agg({\n",
    "    'accuracy': ['mean', 'std'],\n",
    "    'balanced_accuracy': ['mean', 'std'],\n",
    "    'macro_f1': ['mean', 'std'],\n",
    "    'cohens_kappa': ['mean', 'std'],\n",
    "    'matthews_corrcoef': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "# Для удобства чтения переименуем колонки\n",
    "summary.columns = ['_'.join(col).strip() for col in summary.columns.values]\n",
    "summary = summary.reset_index()\n",
    "\n",
    "print(\"Сводные результаты экспериментов:\")\n",
    "display(summary)\n",
    "\n",
    "# Таблица лучших результатов по macro_f1_mean\n",
    "best_results = summary.loc[summary.groupby(['model', 'batch_size'])['macro_f1_mean'].idxmax()]\n",
    "print(\"\\nЛучшие результаты по каждой модели (по Macro F1):\")\n",
    "display(best_results[['model', 'strategy', 'batch_size', 'macro_f1_mean', 'macro_f1_std']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b370e",
   "metadata": {},
   "source": [
    "## Финальный вывод\n",
    "Эксперименты показали, что для классификации планктона на малом и несбалансированном датасете оптимальной является современная архитектура ConvNeXt-Tiny с полным дообучением, обеспечивающая 96.78% Macro F1-score при batch_size=16. Стратегия полного дообучения превзошла частичное дообучение и обучение только классификатора, что указывает на необходимость адаптации всей сети к специфике микроскопических изображений.\n",
    "\n",
    "Ожидаемо, обучение с нуля (PlanktonNet) показало низкие результаты (5.18-8.28% Macro F1), подтверждая критическую важность transfer learning при ограниченном объеме данных. Неожиданным результатом стала крайне низкая эффективность EfficientNet-B4 (5.09-7.18% Macro F1), что может объясняться несовместимостью сложной архитектуры с малым датасетом или необходимостью специальной настройки гиперпараметров.\n",
    "\n",
    "Влияние размера батча оказалось незначительным для качественных моделей, хотя batch_size=16 показал небольшое преимущество. Набор метрик, устойчивых к дисбалансу (Macro F1, Balanced Accuracy, Matthews Correlation Coefficient), подтвердил свою адекватность для объективной оценки моделей.\n",
    "\n",
    "**Рекомендации для дальнейшего улучшения**\n",
    "Для повышения качества классификации рекомендуется собрать дополнительный датасет, особенно для миноритарных классов Leegaardiella_ovalis и amoeba, что позволит преодолеть фундаментальное ограничение текущего исследования. Следует рассмотреть другие современные архитектуры (например, Vision Transformers или Swin Transformer) и экспериментировать с ансамблевыми методами для повышения устойчивости предсказаний. Также целесообразно проверить влияние различных размеров батча и других гиперпараметров, чтобы оптимизировать обучение на малых и несбалансированных датасетах."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
